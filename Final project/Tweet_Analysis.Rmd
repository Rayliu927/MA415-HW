---
title: "Final_project"
author: "Zirui Liu"
date: "5/3/2018"
output: html_document
---

## Introduction

On June 14, 2014, LeBron James opted out of his contract and later that month he decided to return his home team, Cleveland Cavaliars. The team, Cleveland Cavaliars had compiled a league worst 97-215 records in the past four seasons before LeBron's return In 2016, after 52 years without a championship in a major sport, Cleveland wears the crown, bestowed by basketballâ€™s forever king. Toronto Raptors leading by NBA All Stars: DeMar DeRozan and Kyle Lowry becomes one of the strongest team in the east conference. However, they have never beated Cleveland Cavaliars in the playoffs after LeBron James returned. Although, Toronto Raptors is the No.1 seed in east conference this year, Cleveland leads 3-0 as I am writing this.

## Data

The data I use for this project is from NBA Advanced Stats:(https://stats.nba.com/) and tweets mentioning this two teams from twitter api. From the data I have, I want to visulize the contribution LeBron James to the team and analyze the tweets meesage about the game.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(warn = -1)
library(twitteR)
library(tidyverse)
library(ggplot2)
library(tidytext)
library(stringr)
library(scales)
library(wordcloud2)
library(htmlwidgets)
library(tidyr)
library(dplyr)
library(wordcloud)
data(stop_words)


# add customized stop words
stop_words <- add_row(stop_words, word = "t.co", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "https", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "http", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "rt", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "0", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "1", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "2", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "3", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "9", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "03", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "6", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "4", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "05", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "2018", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "https", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "http", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "t.co", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "4zzhmmngci", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "1", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "2", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "3", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "de", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "amp", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "NA", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "FALSE", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "twitter", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "android", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "therealjrsmith", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "20", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "10", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "qulsgpq1kd", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "gkcirtnkyy", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "qflfyixfax", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "l5hxyww94b", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "50wkjztare", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "8", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "14", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "oprahside", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "hsqvlvpuxz", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "qflfyixfax", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "v8epreriz8", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "wzugyb5bnd", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "I5hxyww94b", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "sound", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "cloud", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "flapper", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "rapper", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "epwkh87zwp", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "50wkjzfdre", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "xyx3aupidp", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "yahboyahmed", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "jemelehil", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "rkad92hm1z", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "shahbazmkhan", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "jemelehil", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "lakeshowyo", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "zism1j8isk", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "earzbtiydx", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "2ze2a1f9nc", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "zsxdkscj16", lexicon = "SMART")


# Get tidy version of tweets (The address need to be changed)
cavs <- read.delim("/Users/mac/Desktop/GitHub/MA415-HW/Final\ project/cavs.txt", header=FALSE)
raptors <- read.delim("/Users/mac/Desktop/GitHub/MA415-HW/Final\ project/raptors.txt", header = FALSE)
after_cavs <- read.delim("/Users/mac/Desktop/GitHub/MA415-HW/Final\ project/after_cavs.txt", header=FALSE)
after_raptors <- read.delim("/Users/mac/Desktop/GitHub/MA415-HW/Final\ project/after_raptors.txt", header = FALSE)
# The directory address of speech text might be different.

# Read text
tidy_cavs<- data_frame(paragraph = 149, text = as.character(cavs$V1)) %>% 
  unnest_tokens(word, text)
tidy_raptors <- data_frame(paragraph = 149, text= as.character(raptors$V1)) %>% 
  unnest_tokens(word, text)
tidy_after_cavs<- data_frame(paragraph = 149, text = as.character(after_cavs$V1)) %>% 
  unnest_tokens(word, text)
tidy_after_raptors <- data_frame(paragraph = 149, text= as.character(after_raptors$V1)) %>% 
  unnest_tokens(word, text)

```


Helper function
```{r}

getFreq <- function(file, name) {
  text <- readLines(file)
  text_df <- data_frame(line = 1:length(text), text = text )
  text_df <- text_df %>%
    unnest_tokens(word, text) %>% 
    count(word, sort = TRUE) %>% 
    filter(n > 200) %>% 
    anti_join(stop_words, by = "word") %>% 
    mutate(word = reorder(word, n)) %>% 
    ggplot(aes(word, n), col = "blue") +
    geom_col() +
    xlab(NULL) +
    ggtitle(name) +
    coord_flip()
}

getWordCloud <- function(file, min_freq, max_word) {
  df <- getTidyTibble(file)
  cloud <- df %>% anti_join(stop_words, by = "word") %>%
  count(word, sort = TRUE)
  temp <- wordcloud(words = cloud$word, freq = cloud$n, min.freq = min_freq,
          max.words=max_word, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))
  return(temp)
}

getTidyTibble <- function(file) {
  text <- readLines(file)
  df <- data_frame(line = 1:length(text), text = text)
  df <- df %>% 
    unnest_tokens(word, text) %>% 
    anti_join(stop_words)
  return(df)
}
```

# Team scores comparison between Cleveland Cavaliers and Toronto Raptors
Red -- Raptors
&nbsp;
Blue -- Cavaliers
```{r}
data_total <- read.csv("cavs_raptors.csv")
data_total <- as.tibble(data_total)
data_total$DATE <- as.Date(data_total$DATE)
daily <- filter(data_total)
ggplot(daily, aes(x = DATE)) + 
  geom_line(aes(y = CLE.PTS), colour="blue", size = 0.5) + 
  geom_line(aes(y = Raptors.PTS), colour="red", size = 0.5) +
  labs(subtitle="Cavaliers Vs Raptors", 
       y="Score", 
       x="Date", 
       title="Team scores comparison",
       caption = "Source: NBA Stats")

```

As we can see from the graph, the blue line represents Cavaliers' score and the red line represents Raptors' score. The data I chose is after LeBron James returned to Cleveland Cavaliers. We can easily see that even though there are some very close games, most of the time, Clevelead beat Toronto.


# Points LeBron James scores

Red -- Points LBJ scores

```{r}
data_total <- read.csv("cavs_raptors.csv")
data_total <- as.tibble(data_total)
data_total$DATE <- as.Date(data_total$DATE)
daily <- filter(data_total)
ggplot(daily, aes(x = DATE)) + 
  geom_line(aes(y = LBJ.PTS), colour="red", size = 0.5) +
  labs(y="points", 
       x="Date", 
       title="LeBron James' contribution to the team",
       caption = "Source: NBA Stats")

```
The graph shows the points that LeBron James scored during the playoffs this year. Even though the points he scored vary very differently, the average points he got is relatively high. We can see approximately how much LeBron James has contributed to the game.

# Percentage of points LeBron James contributes to the total score

Red -- Points LBJ scores to the whole team score percentage

```{r}
data_total <- read.csv("cavs_raptors.csv")
data_total <- as.tibble(data_total)
data_total$DATE <- as.Date(data_total$DATE)
daily <- filter(data_total)
ggplot(daily, aes(x = DATE)) + 
  geom_line(aes(y = LBJ_PCG), colour="red", size = 0.5) +
  labs(y="points", 
       x="Date", 
       title="LeBron James' contribution to the team",
       caption = "Source: NBA Stats")

```
The graph show the percentage of the points he scores to the points that the whole team scores. From the graph, we can see that LeBron James has contributed more than 25% of points in the game. Since, in oen basketball game, there are usually eight people rotation, about 30% of average points LeBron James has contributed in the game is very large.

# Points LeBron James scores during 2017-2018 season
```{r}
data_total <- read.csv("LBJ_2017_2018.csv")
data_total <- as.tibble(data_total)
ggplot(data_total, aes(x = MATCH, y = PTS)) + 
  geom_point(colour="red", size = 0.5) +
  labs(y="points", 
       x="MATCH", 
       title="Points LeBron James scores during 2017-2018 season",
       caption = "Source: NBA Stats")

```




This is the graph shows the distribution of points that LeBron James scores during 2017-2018 season. It is easy for us to see that in some games, LeBron James scores more than 50 points, but in some games, he scores only 10 points. It makes sense that, in some games, basketball coaches might want to change the strategies of game. Therefore, players might score less points in some games that in others. From the graph, LeBron James score more points in one game than most of other players in the leagure. 

# Call Twitter api and store tweets in csv file
```{r}
consumer_key <- "VovdJylrMlUqYcKuCC7ey9SSZ"
consumer_secret <- "bMBSQpFdBqQ77qizilP8ymBon0OFgXoMW2XhhcJxAth9VUU2Iu"
access_token <- "992102228239503360-R2BB3ODGfT99DzWvP2XxI2LRSnVvJLs"
access_secret <- "e8npyQ749tiL5ZJF4O3B4idAWiCDCf4Z935e55Tew5HWh"
setup_twitter_oauth(consumer_key, consumer_secret, access_token, access_secret)

# Get tweets about Cleveland Cavaliers
tw = twitteR::searchTwitter('cavs', n = 5000, since = '2018-5-03', retryOnRateLimit = 4)
cavs = twitteR::twListToDF(tw)
clean_cavs <- as_tibble(cavs)
clean_cavs <- subset(clean_cavs, select = c(1))
write.csv(clean_cavs, file = "cavs.csv")

# Get tweets about Toronto Raptors
tw = twitteR::searchTwitter('Raptors', n = 5000, since = '2018-5-03', retryOnRateLimit = 4)
raptors = twitteR::twListToDF(tw)
clean_raptors <- as_tibble(raptors)
clean_raptors <- subset(clean_raptors, select = c(1))
write.csv(clean_raptors, file = "raptors.csv")


# Get tweets about Cleveland Cavaliers after game
tw = twitteR::searchTwitter('cavs', n = 5000, since = '2018-5-04', retryOnRateLimit = 4)
cavs = twitteR::twListToDF(tw)
clean_cavs <- as_tibble(cavs)
clean_cavs <- subset(clean_cavs, select = c(1))
write.csv(clean_cavs, file = "after_cavs.csv")

# Get tweets about Toronto Raptors after game
tw = twitteR::searchTwitter('Raptors', n = 5000, since = '2018-5-04', retryOnRateLimit = 4)
raptors = twitteR::twListToDF(tw)
clean_raptors <- as_tibble(raptors)
clean_raptors <- subset(clean_raptors, select = c(1))
write.csv(clean_raptors, file = "after_raptors.csv")

```

I used Twitter api to extract tweets mentioning "cavs" and "raptors" before and after May 3rd game. Also, I stored them into different csv file.

# read csv file and clean data
```{r}
cavs = readLines("cavs.csv")
write.table(cavs,"cavs.txt",sep="\t",row.names=FALSE)

raptors = readLines("raptors.csv")
write.table(raptors,"raptors.txt",sep="\t",row.names=FALSE)

cavs = readLines("after_cavs.csv")
write.table(cavs,"after_cavs.txt",sep="\t",row.names=FALSE)

raptors = readLines("after_raptors.csv")
write.table(raptors,"after_raptors.txt",sep="\t",row.names=FALSE)
```
This chunk basically transform csv file into txt file for future analysis.

# Get frequencey of words in tweets before May 3rd game
```{r}
cavs <-  getFreq('cavs.txt', 'Most used words in tweet mentioing cavs')
raptors <- getFreq('raptors.txt', 'Most used words in tweets mentioing raptors')

cavs
raptors

```


# Get frequencey of words in tweets after May 3rd game
```{r}
cavs <-  getFreq('after_cavs.txt', 'Most used words in tweet mentioing cavs')
raptors <- getFreq('after_raptors.txt', 'Most used words in tweets mentioing raptors')

cavs
raptors

```

As we can see from the grpah, fans from both teams mentioning the names of two teams the most. It is also interesting to see that fans from both teams mentioning LeBron James' name a lot and this may be caused by the amazing performance LBJ has in this series. In the last 3 games, LBJ made the cluch shot twice. Also, we can see some phrasees like "wethenorth" and "whateverittakes" that represent the winning determination. 

# Word cloud before May 3rd game
```{r}
library(wordcloud)

cavs_cloud <- getWordCloud('cavs.txt', 100, 300)
raptors_cloud <- getWordCloud('raptors.txt', 100, 300)

cavs_cloud
raptors_cloud


```

# Word cloud after May 3rd game
```{r}

after_cavs_cloud <- getWordCloud('after_cavs.txt', 100, 300)
after_raptors_cloud <- getWordCloud('after_raptors.txt', 100, 300)

after_cavs_cloud
after_raptors_cloud

```

In the word cloud, the more frequent words appear bigger. It helps us see the frequency of words in a more visual way. Some of the words such as: lebron, game, winner, and sportscenter are the words appear very oftern. This means that these certain topics are most heating discussed topics. 

## Positive/negative words for Cavs tweets before May 3rd game
```{r message=FALSE}
cavs_word_counts <- tidy_cavs %>% 
  inner_join(get_sentiments("bing")) %>% 
  count(word, sentiment, sort = TRUE)

cavs_word_counts %>% 
  group_by(sentiment) %>% 
  top_n(10) %>% 
  ungroup() %>% 
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(y = "Sentiments",
       x = NULL) +
  ggtitle("Tweets about Cavs before May 3rd game") +
  coord_flip()
```

## Positive/negative words for Raptors tweets before May 3rd game
```{r message=FALSE}
raptors_word_counts <- tidy_raptors %>% 
  inner_join(get_sentiments("bing")) %>% 
  count(word, sentiment, sort = TRUE)

raptors_word_counts %>% 
  group_by(sentiment) %>% 
  top_n(10) %>% 
  ungroup() %>% 
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(y = "Sentiments",
       x = NULL) +
  ggtitle("Tweets about Raptors before May 3rd game") +
  coord_flip()
```

## Positive/negative words for Cavs tweets after May 3rd game
```{r message=FALSE}
cavs_word_counts <- tidy_after_cavs %>% 
  inner_join(get_sentiments("bing")) %>% 
  count(word, sentiment, sort = TRUE)

cavs_word_counts %>% 
  group_by(sentiment) %>% 
  top_n(10) %>% 
  ungroup() %>% 
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(y = "Sentiments",
       x = NULL) +
  ggtitle("Tweets about Cavs after May 3rd game") +
  coord_flip()
```

## Positive/negative words for Raptors tweets after May 3rd game
```{r message=FALSE}
raptors_word_counts <- tidy_after_raptors %>% 
  inner_join(get_sentiments("bing")) %>% 
  count(word, sentiment, sort = TRUE)

raptors_word_counts %>% 
  group_by(sentiment) %>% 
  top_n(10) %>% 
  ungroup() %>% 
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(y = "Sentiments",
       x = NULL) +
  ggtitle("Tweets about Raptors before May 3rd game") +
  coord_flip()
```




From the positive and negative words sentiment analysis, it is hard to see which side has stronger emotion of winning because fans from both sides could mention their opponent team. Also, some of the words that we typically consider positive or negative do not represent the same meaning when peopel tweet about it. However, an interesting fact that I have found is that positive words tend to appear more oftern than negative words, and the meannings of some negative words like: "sorry", "crazy", and "scary" should be determined in the context. Overall, the atmosphere of watching playoffs games on Twitter is very friendly. People always get excited about the game instead of attacking opponent teams.

## More sentiment analysis for CAVS
```{r}
# Sentiment analysis with nrc
nrc_joy <- get_sentiments("nrc") %>% 
  filter(sentiment == "joy")
nrc_anger <- get_sentiments("nrc") %>% 
  filter(sentiment == "anger")
nrc_anticipation <- get_sentiments("nrc") %>% 
  filter(sentiment == "anticipation")
nrc_sadness <- get_sentiments("nrc") %>% 
  filter(sentiment == "sadness")

# Cavs sentiment analysis with nrc
cavs_joy <- tidy_cavs %>%
  inner_join(nrc_joy) %>%
  count(word, sort = TRUE) %>%
  filter(n > 10) %>%
  mutate(word = reorder(word, n))

cavs_anger <- tidy_cavs %>%
  inner_join(nrc_anger) %>%
  count(word, sort = TRUE) %>%
  filter(n > 10) %>%
  mutate(word = reorder(word, n))

cavs_anticipation <- tidy_cavs %>%
  inner_join(nrc_anticipation) %>%
  count(word, sort = TRUE) %>%
  filter(n > 10) %>%
  mutate(word = reorder(word, n))

cavs_sadness <- tidy_cavs %>%
  inner_join(nrc_sadness) %>%
  count(word, sort = TRUE) %>%
  filter(n > 10) %>%
  mutate(word = reorder(word, n))

gridExtra::grid.arrange(
  ggplot(cavs_joy, aes(word, n)) +
    geom_col() +
    xlab(NULL) +
    coord_flip() +
    ggtitle("Cavs Joy"),
  ggplot(cavs_anger, aes(word, n)) +
    geom_col() +
    xlab(NULL) +
    coord_flip() +
    ggtitle("Cavs Anger"),
  ggplot(cavs_anticipation, aes(word, n)) +
    geom_col() +
    xlab(NULL) +
    coord_flip() +
    ggtitle("Cavs Anticipation"),
  ggplot(cavs_sadness, aes(word, n)) +
    geom_col() +
    xlab(NULL) +
    coord_flip() +
    ggtitle("Cavs Sadness"),
  nrow=1
)

```

## More sentiment analysis for Raptors
```{r}
# Sentiment analysis with nrc
nrc_joy <- get_sentiments("nrc") %>% 
  filter(sentiment == "joy")
nrc_anger <- get_sentiments("nrc") %>% 
  filter(sentiment == "anger")
nrc_anticipation <- get_sentiments("nrc") %>% 
  filter(sentiment == "anticipation")
nrc_sadness <- get_sentiments("nrc") %>% 
  filter(sentiment == "sadness")

# Raptors sentiment analysis with nrc
raptors_joy <- tidy_raptors %>%
  inner_join(nrc_joy) %>%
  count(word, sort = TRUE) %>%
  filter(n > 10) %>%
  mutate(word = reorder(word, n))

raptors_anger <- tidy_raptors %>%
  inner_join(nrc_anger) %>%
  count(word, sort = TRUE) %>%
  filter(n > 10) %>%
  mutate(word = reorder(word, n))

raptors_anticipation <- tidy_raptors %>%
  inner_join(nrc_anticipation) %>%
  count(word, sort = TRUE) %>%
  filter(n > 10) %>%
  mutate(word = reorder(word, n))

raptors_sadness <- tidy_raptors %>%
  inner_join(nrc_sadness) %>%
  count(word, sort = TRUE) %>%
  filter(n > 10) %>%
  mutate(word = reorder(word, n))

gridExtra::grid.arrange(
  ggplot(raptors_joy, aes(word, n)) +
    geom_col() +
    xlab(NULL) +
    coord_flip() +
    ggtitle("Raptors Joy"),
  ggplot(raptors_anger, aes(word, n)) +
    geom_col() +
    xlab(NULL) +
    coord_flip() +
    ggtitle("Raptors Anger"),
  ggplot(raptors_anticipation, aes(word, n)) +
    geom_col() +
    xlab(NULL) +
    coord_flip() +
    ggtitle("Raptors Anticipation"),
  ggplot(raptors_sadness, aes(word, n)) +
    geom_col() +
    xlab(NULL) +
    coord_flip() +
    ggtitle("Raptors Sadness"),
  nrow=1
)
```

From the more specific sentiment analysis, we can see more clearly which words represent: joy, anger, anticipation and sadness. However, some words like: "shot", "music", and "crazy" should be considered sadness sentiment in tweets about basketball. If we exclude these words in our analysis, we can see that words that represent joy and anticipation are more freqently found on tweets. 

