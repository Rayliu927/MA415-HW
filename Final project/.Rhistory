filter(n > 10) %>%
mutate(word = reorder(word, n))
raptors_sadness <- tidy_raptors %>%
inner_join(nrc_sadness) %>%
count(word, sort = TRUE) %>%
filter(n > 10) %>%
mutate(word = reorder(word, n))
gridExtra::grid.arrange(
ggplot(raptors_joy, aes(word, n)) +
geom_col() +
xlab(NULL) +
coord_flip() +
ggtitle("Raptors Joy"),
ggplot(raptors_anger, aes(word, n)) +
geom_col() +
xlab(NULL) +
coord_flip() +
ggtitle("Raptors Anger"),
ggplot(raptors_anticipation, aes(word, n)) +
geom_col() +
xlab(NULL) +
coord_flip() +
ggtitle("Raptors Anticipation"),
ggplot(inner_join, aes(word, n)) +
geom_col() +
xlab(NULL) +
coord_flip() +
ggtitle("Raptors Sadness"),
nrow=1
)
# Sentiment analysis with nrc
nrc_joy <- get_sentiments("nrc") %>%
filter(sentiment == "joy")
nrc_anger <- get_sentiments("nrc") %>%
filter(sentiment == "anger")
nrc_anticipation <- get_sentiments("nrc") %>%
filter(sentiment == "anticipation")
nrc_sadness <- get_sentiments("nrc") %>%
filter(sentiment == "sadness")
# Trump sentiment analysis with nrc
raptors_joy <- tidy_raptors %>%
inner_join(nrc_joy) %>%
count(word, sort = TRUE) %>%
filter(n > 10) %>%
mutate(word = reorder(word, n))
raptors_anger <- tidy_raptors %>%
inner_join(nrc_anger) %>%
count(word, sort = TRUE) %>%
filter(n > 10) %>%
mutate(word = reorder(word, n))
raptors_anticipation <- tidy_raptors %>%
inner_join(nrc_anticipation) %>%
count(word, sort = TRUE) %>%
filter(n > 10) %>%
mutate(word = reorder(word, n))
raptors_sadness <- tidy_raptors %>%
inner_join(nrc_sadness) %>%
count(word, sort = TRUE) %>%
filter(n > 10) %>%
mutate(word = reorder(word, n))
gridExtra::grid.arrange(
ggplot(raptors_joy, aes(word, n)) +
geom_col() +
xlab(NULL) +
coord_flip() +
ggtitle("Raptors Joy"),
ggplot(raptors_anger, aes(word, n)) +
geom_col() +
xlab(NULL) +
coord_flip() +
ggtitle("Raptors Anger"),
ggplot(raptors_anticipation, aes(word, n)) +
geom_col() +
xlab(NULL) +
coord_flip() +
ggtitle("Raptors Anticipation"),
ggplot(raptors_sadness, aes(word, n)) +
geom_col() +
xlab(NULL) +
coord_flip() +
ggtitle("Raptors Sadness"),
nrow=1
)
knitr::opts_chunk$set(echo = TRUE)
options(warn = -1)
library(twitteR)
library(tidyverse)
library(ggplot2)
library(tidytext)
library(stringr)
library(scales)
library(wordcloud2)
library(htmlwidgets)
library(tidyr)
library(dplyr)
library(wordcloud)
data(stop_words)
# add customized stop words
stop_words <- add_row(stop_words, word = "t.co", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "https", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "realdonaldtrump", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "http", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "rt", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "0", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "1", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "2", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "3", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "9", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "03", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "6", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "4", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "05", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "2018", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "elon", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "musk", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "trump", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "donald", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "rt", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "https", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "http", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "t.co", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "4zzhmmngci", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "1", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "2", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "3", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "de", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "amp", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "NA", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "FALSE", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "twitter", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "android", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "therealjrsmith", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "20", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "10", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "qulsgpq1kd", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "gkcirtnkyy", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "qflfyixfax", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "l5hxyww94b", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "50wkjztare", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "8", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "14", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "oprahside", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "hsqvlvpuxz", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "qflfyixfax", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "v8epreriz8", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "wzugyb5bnd", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "I5hxyww94b", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "sound", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "cloud", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "flapper", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "rapper", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "epwkh87zwp", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "50wkjzfdre", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "xyx3aupidp", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "yahboyahmed", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "jemelehil", lexicon = "SMART")
cavs = readLines("cavs.csv")
write.table(cavs,"cavs.txt",sep="\t",row.names=FALSE)
raptors = readLines("raptors.csv")
write.table(raptors,"raptors.txt",sep="\t",row.names=FALSE)
cavs = readLines("after_cavs.csv")
write.table(cavs,"after_cavs.txt",sep="\t",row.names=FALSE)
raptors = readLines("after_raptors.csv")
write.table(raptors,"after_raptors.txt",sep="\t",row.names=FALSE)
after_cavs_df <- getTidyTibble('after_cavs.txt')
after_raptors_df <- getTidyTibble('after_raptors.txt')
after_cavsCloud <- after_cavs_df %>%
count(word, sort = TRUE)
after_raptorsCloud <- after_raptors_df %>%
count(word, sort = TRUE)
wordcloud(words = after_cavsCloud$word, freq = after_cavsCloud$n, min.freq = 125,
max.words=300, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = after_raptorsCloud$word, freq = after_raptorsCloud$n, min.freq = 125,
max.words=300, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
knitr::opts_chunk$set(echo = TRUE)
options(warn = -1)
library(twitteR)
library(tidyverse)
library(ggplot2)
library(tidytext)
library(stringr)
library(scales)
library(wordcloud2)
library(htmlwidgets)
library(tidyr)
library(dplyr)
library(wordcloud)
data(stop_words)
# add customized stop words
stop_words <- add_row(stop_words, word = "t.co", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "https", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "realdonaldtrump", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "http", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "rt", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "0", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "1", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "2", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "3", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "9", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "03", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "6", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "4", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "05", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "2018", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "elon", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "musk", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "trump", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "donald", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "rt", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "https", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "http", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "t.co", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "4zzhmmngci", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "1", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "2", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "3", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "de", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "amp", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "NA", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "FALSE", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "twitter", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "android", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "therealjrsmith", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "20", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "10", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "qulsgpq1kd", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "gkcirtnkyy", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "qflfyixfax", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "l5hxyww94b", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "50wkjztare", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "8", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "14", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "oprahside", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "hsqvlvpuxz", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "qflfyixfax", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "v8epreriz8", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "wzugyb5bnd", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "I5hxyww94b", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "sound", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "cloud", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "flapper", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "rapper", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "epwkh87zwp", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "50wkjzfdre", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "xyx3aupidp", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "yahboyahmed", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "jemelehil", lexicon = "SMART")
after_cavs_df <- getTidyTibble('after_cavs.txt')
after_raptors_df <- getTidyTibble('after_raptors.txt')
after_cavsCloud <- after_cavs_df %>%
count(word, sort = TRUE)
after_raptorsCloud <- after_raptors_df %>%
count(word, sort = TRUE)
wordcloud(words = after_cavsCloud$word, freq = after_cavsCloud$n, min.freq = 125,
max.words=300, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = after_raptorsCloud$word, freq = after_raptorsCloud$n, min.freq = 125,
max.words=300, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
install.packages("shiny")
library("shiny", lib.loc="~/Library/R/3.4/library")
install.packages("shinydashboard")
library("shinydashboard", lib.loc="~/Library/R/3.4/library")
runApp('Desktop/GitHub/MA415-HW/Assignment5/Shiny_app.R')
install.packages("rsconnect")
library("rsconnect", lib.loc="~/Library/R/3.4/library")
runApp('Desktop/GitHub/MA415-HW/Assignment5/Shiny_app.R')
runApp('Desktop/MA415-Final-Project-NBA-3-Pointer-Analysis-master/Shiny.R')
library(shiny); runApp('Desktop/MA415-Final-Project-NBA-3-Pointer-Analysis-master/Shiny.R')
runApp('Downloads/shiny/test11')
install.packages("DT")
library("DT", lib.loc="~/Library/R/3.4/library")
runApp('Downloads/shiny/test11')
knitr::opts_chunk$set(echo = TRUE)
options(warn = -1)
library(twitteR)
library(tidyverse)
library(ggplot2)
library(tidytext)
library(stringr)
library(scales)
library(wordcloud2)
library(htmlwidgets)
library(tidyr)
library(dplyr)
library(wordcloud)
data(stop_words)
# add customized stop words
stop_words <- add_row(stop_words, word = "t.co", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "https", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "realdonaldtrump", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "http", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "rt", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "0", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "1", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "2", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "3", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "9", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "03", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "6", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "4", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "05", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "2018", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "elon", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "musk", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "trump", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "donald", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "rt", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "https", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "http", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "t.co", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "4zzhmmngci", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "1", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "2", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "3", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "de", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "amp", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "NA", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "FALSE", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "twitter", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "android", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "therealjrsmith", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "20", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "10", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "qulsgpq1kd", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "gkcirtnkyy", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "qflfyixfax", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "l5hxyww94b", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "50wkjztare", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "8", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "14", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "oprahside", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "hsqvlvpuxz", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "qflfyixfax", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "v8epreriz8", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "wzugyb5bnd", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "I5hxyww94b", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "sound", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "cloud", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "flapper", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "rapper", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "epwkh87zwp", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "50wkjzfdre", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "xyx3aupidp", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "yahboyahmed", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "jemelehil", lexicon = "SMART")
#Custom functions to simplify code
getWordFreq <- function(file, freqMin, name) {
text <- readLines(file)
text_df <- data_frame(line = 1:length(text), text = text )
text_df <- text_df %>%
unnest_tokens(word, text) %>%
count(word, sort = TRUE) %>%
filter(n > freqMin) %>%
anti_join(stop_words, by = "word") %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col() +
xlab(NULL) +
ggtitle(name) +
coord_flip()
}
getTidyTibble <- function(file) {
text <- readLines(file)
df <- data_frame(line = 1:length(text), text = text)
df <- df %>%
unnest_tokens(word, text) %>%
anti_join(stop_words)
return(df)
}
data_total <- read.csv("cavs_raptors.csv")
data_total <- as.tibble(data_total)
data_total$DATE <- as.Date(data_total$DATE)
daily <- filter(data_total)
ggplot(daily, aes(x = DATE)) +
geom_line(aes(y = CLE.PTS), colour="blue", size = 0.5) +
geom_line(aes(y = Raptors.PTS), colour="red", size = 0.5) +
labs(subtitle="Cavaliers Vs Raptors",
y="Score",
x="Date",
title="Team scores comparison",
caption = "Source: NBA Stats")
knitr::opts_chunk$set(echo = TRUE)
options(warn = -1)
library(twitteR)
library(tidyverse)
library(ggplot2)
library(tidytext)
library(stringr)
library(scales)
library(wordcloud2)
library(htmlwidgets)
library(tidyr)
library(dplyr)
library(wordcloud)
data(stop_words)
# add customized stop words
stop_words <- add_row(stop_words, word = "t.co", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "https", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "http", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "rt", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "0", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "1", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "2", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "3", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "9", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "03", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "6", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "4", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "05", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "2018", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "https", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "http", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "t.co", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "4zzhmmngci", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "1", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "2", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "3", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "de", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "amp", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "NA", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "FALSE", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "twitter", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "android", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "therealjrsmith", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "20", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "10", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "qulsgpq1kd", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "gkcirtnkyy", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "qflfyixfax", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "l5hxyww94b", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "50wkjztare", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "8", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "14", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "oprahside", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "hsqvlvpuxz", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "qflfyixfax", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "v8epreriz8", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "wzugyb5bnd", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "I5hxyww94b", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "sound", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "cloud", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "flapper", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "rapper", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "epwkh87zwp", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "50wkjzfdre", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "xyx3aupidp", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "yahboyahmed", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "jemelehil", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "rkad92hm1z", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "shahbazmkhan", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "jemelehil", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "lakeshowyo", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "zism1j8isk", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "earzbtiydx", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "2ze2a1f9nc", lexicon = "SMART")
stop_words <- add_row(stop_words, word = "zsxdkscj16", lexicon = "SMART")
# Get tidy version of tweets (The address need to be changed)
cavs <- read.delim("/Users/mac/Desktop/GitHub/MA415-HW/Final\ project/cavs.txt", header=FALSE)
raptors <- read.delim("/Users/mac/Desktop/GitHub/MA415-HW/Final\ project/raptors.txt", header = FALSE)
after_cavs <- read.delim("/Users/mac/Desktop/GitHub/MA415-HW/Final\ project/after_cavs.txt", header=FALSE)
after_raptors <- read.delim("/Users/mac/Desktop/GitHub/MA415-HW/Final\ project/after_raptors.txt", header = FALSE)
# The directory address of speech text might be different.
# Read text
tidy_cavs<- data_frame(paragraph = 149, text = as.character(cavs$V1)) %>%
unnest_tokens(word, text)
tidy_raptors <- data_frame(paragraph = 149, text= as.character(raptors$V1)) %>%
unnest_tokens(word, text)
tidy_after_cavs<- data_frame(paragraph = 149, text = as.character(after_cavs$V1)) %>%
unnest_tokens(word, text)
tidy_after_raptors <- data_frame(paragraph = 149, text= as.character(after_raptors$V1)) %>%
unnest_tokens(word, text)
getFreq <- function(file, name) {
text <- readLines(file)
text_df <- data_frame(line = 1:length(text), text = text )
text_df <- text_df %>%
unnest_tokens(word, text) %>%
count(word, sort = TRUE) %>%
filter(n > 200) %>%
anti_join(stop_words, by = "word") %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n), col = "blue") +
geom_col() +
xlab(NULL) +
ggtitle(name) +
coord_flip()
}
getWordCloud <- function(file, min_freq, max_word) {
df <- getTidyTibble(file)
cloud <- df %>% anti_join(stop_words, by = "word") %>%
count(word, sort = TRUE)
temp <- wordcloud(words = cloud$word, freq = cloud$n, min.freq = min_freq,
max.words=max_word, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
return(temp)
}
getTidyTibble <- function(file) {
text <- readLines(file)
df <- data_frame(line = 1:length(text), text = text)
df <- df %>%
unnest_tokens(word, text) %>%
anti_join(stop_words)
return(df)
}
library(wordcloud)
cavs_cloud <- getWordCloud('cavs.txt', 100, 300)
raptors_cloud <- getWordCloud('raptors.txt', 100, 300)
cavs_cloud
raptors_cloud
library(shiny); runApp('Desktop/GitHub/MA415-HW/Final project/shiny.R')
